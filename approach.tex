\section{Approach}
\label{sec:approach}
% 5 pages
% input is n triples aligned to a certain vocabulary
% output is json-ld documents structured to support optimized query in ES/document store
% needs a worked example, of why we need nested queries.  pages / offers / phone number
% list six types: offers, phone numbers, pages, etc.
% need to explain when we facet, for example if we facet by phone on phones, you only get one phone.
% the json ld documents generated a denormalize according to how deeply you need to go to support your queries.

% a. explain where we start from. 
% b. data alignment karma/r2rml/sparql construct 
% c. join precompute rdf -> serialize to json-ld -> frame using spark
% d. indexing documents
% describe the operations we need to perform over the doucments


LD-VIEWS are designed to enable end users to efficiently query a collection of entities of the same type and their RDF neighborhood in a prescriptive way.   
This is accomplished by leveraging the concept of views from SQL.  
Views in SQL are used for many reasons: restricting data access, abstracting complexity, and efficiency. 
When a view is the product of many joins, it is often materialized, or pre-computed, to avoid having to pay the enormous expense of the join operations.  
Joins are expensive when the data involved no longer fits in the working memory of a single machine and has to spill to disk.  
Even worse is when the join involves data so large it needs to be distributed across many machines.  
When joins are the primary operation, like many SPARQL queries, the expense is compounded many times over.

LD-VIEWS aims to eliminate expensive join operations by creating a materialized view for each entity type tailored to the query needs of the end users.  
A view is materialized by pre-computing certain joins against other entities in its entities' RDF neighborhoods along prescribed predicate paths.  
The view is then serialized as a collection of denormalized JSON-LD documents with each document containing an entity and the triples in its neighborhood relevant to the desired queries.  
Since the RDF neighborhood is now denormalized and localized into each document, the documents can be partitioned across many machines.
To answer a query, the machines can compute their results independently and only communicate when they need to merge the results like in an aggregation query.
This eliminates the need to recursively expand the candidate result graph across nodes in a clustered triple store database when computing joins.  
Finally, to serve the views, the documents need to be indexed many ways.
The databases that have the necessary indexing and sharding support are the family of document-oriented databases like MongoDB, Couchbase, Solr, and Elasticsearch.  

For generality, our approach to generating views for efficient RDF query processing assumes an RDF graph in N-Triples aligned to a common vocabulary as input.  
A common vocabulary is not a hard requirement, but helps keep the possible combinations of types and properties in the views manageable.
It can be achieved many ways, like by mapping from legacy sources to RDF using R2RML, executing SPARQL construct queries, etc. 

%Each query against the view applies one or more filters to the collection of entities aand then either retrieves entities or aggreperforms a number of set operations on the entities in the collection.    

\subsection{View Definition}
\subsubsection{Nesting}
%Here I need to talk about why we need nesting
\subsubsection{Facets}
%Here I need to talk about why we need facets
\subsubsection{Multiple views}
%Here I need to talk about why we need multiple views

\subsection{Framing}
The JSON-LD standard has an algorithm, called framing, for translating an RDF graph into a collection of trees so it can be serialized as JSON-LD documents. \cite{sporny:jsonld-framing}
The instructions for translating the RDF graph are captured in a JSON document called a frame.  
LD-VIEWS requires a frame for each view.  
We wrote a frame to create a view for each of our major classes: WebPage, Offer, AdultService, Seller, Phone, and Email.  
An example frame for our WebPage view is in figure ~\ref{fig:json_ld_webpage_view}.  
Depending on the application's query needs, more than one frame and view can be created for each class.  

To construct the WebPage view, the source RDF N-Triples and the view's corresponding frame are fed into our implementation of the JSON-LD framing algorithm.  
Previously, the only available implementation of the framing algorithm is in the official JSON-LD libraries.  
While efficient, it is of limited use because it  is single threaded and requires the triples and subsequent documents to fit in memory.
The sheer size of our input dataset and the number of joins necessitated a parallel implementation that could either spill intermediate results to disk or take advantage of the memory available across many machines. 
Initial attempts at implementing the algorithm using Apache Hive were prohibitively slow due to its poor distributed join performance and the excessive IO required by Apache MapReduce.  Applying a single frame on a billion triples took over a day.  
An implementation of the algorithm in Apache Spark can apply a frame to a billion triples in fifteen minutes on a large cluster, due to its ability to cache intermediate results and perform joins in memory.   
\begin{figure}
\vspace{-0.2cm}
\begin{verbatim}
{
  "@type": "WebPage",
  "url": {},
  "publisher": {"@type": "Organization"},
  "mainEntity": {
    "@type": "Offer",
    "seller": {
      "@type": "PersonOrOrganization",
      "telephone": {"@type": "PhoneNumber"},
      "email": {"@type": "EmailAddress"}
    },
    "availableAtOrFrom": {
      "@type": "Place",
      "address": {"@type": "PostalAddress",},
      "geo": {"@type": "GeoCoordinates",}
    },
    "itemOffered": {"@type": "AdultService"},
    "priceSpecification": {"@type": "PriceSpecification"}
  }
}
\end{verbatim}
\caption{JSON-LD Frame for WebPage View}
\label{fig:json_ld_webpage_view}
\vspace{-0.2cm}
\end{figure}
\begin{figure}
\vspace{-0.2cm}
\begin{verbatim}
{
  "a": "http://schema.org/WebPage",
  "publisher": {
    "uri": "http://dig.isi.edu/ht/data/organization/liveescortreviews.com",
    "name": "liveescortreviews.com"
  },
  "description": "arabic princess. SPECIAL CALL NOW 100 SPECIAL ! ...",
  "url": "http://liveescortreviews.com/ad/boston/347-471-3027/1/312634",
  "uri": "http://dig.isi.edu/ht/data/webpage/...",
  "dateCreated": "2015-03-10T23:24:26",
  "mainEntity": {
    "availableAtOrFrom": {
      "address": {"addressLocality": "Boston","addressRegion": "Ma"}
    },
    "uri": "http://dig.isi.edu/ht/data/offer/...",
    "seller": {
      "telephone": {
        "uri": "http://dig.isi.edu/ht/data/phone/1-3474713027",
        "name": "3474713027"
      },
      "uri": "http://dig.isi.edu/ht/data/seller/..."
    },
    "itemOffered": {
      "age": "19",
      "uri": "http://dig.isi.edu/ht/data/adultservice/..."
    },
    "validFrom": "2015-03-10T23:24:26"
  },
  "name": "Live Escort Reviews - 347-471-3027 - arabic princess..."
}
\end{verbatim}
\vspace{-0.2cm}
\caption{Example framed WebPage document for view}
\label{fig:framed-webpage}
\end{figure}
% need to talk about indexing here
\subsection{Indexing}
After the frames have been applied, the result is collections of JSON-LD documents, one collection per view.  
Each document contains the RDF neighborhood around the entity that corresponds to the type associated with a view.  
To support the end user queries, the documents need to be indexed accordingly.  

For maximum query performance, we create an inverted index for each field and the path associated with each nested field, which the framer has created by pre-computing the joins.  
For our example web page view,  we index both the schema:dateCreated of the web page in figure \label{fig:json_ld_webpage_view} and the schema:name of the schema:mainEntity/schema:seller/schema:telephone.  
This allows us to find web pages that were crawled on the same day or find web pages that mention a particular telephone.  

Fortunately, Elasticsearch can handle this indexing process efficiently, creating the multitude of indexes simultaneously.  
Since Elasticsearch is primarily a text search engine it supports incredible flexibility in indexing free text.  
However, the index type chosen can also be informed by the RDFS type of the objects, which enables us to perform operations like date range and geospatial queries efficiently.
% Insert discussion on size of index on discuss versus input size. 

Admittedly, this represents an extreme approach compared to the common indexing approaches normally seen in RDF Triple Stores.  
According to \cite{luo2012storing}, without insight into the expected query load, the triple store must make a best effort to support ad hoc queries.  
As such, the chapter describes the handful indexes that can be built by permuting the subject, predicate, object, and optional context graph values that make up a triple or quad.
These indexes can either contain references to triples in unclustered indexes, or materialize them in clustered indexes, trading performance for space.
Virtuoso can create bitmaps for predicate object pairs to speed subject lookups, which can be quickly combined to satisfy multiple constraints, which is analogous to how Elasticsearch applies many filters. 
The important distinction in Virtuoso is that these bitmaps only enable filtering properties immediate to a subject, not property paths.
If the property paths are many steps away, the joins along the property paths must still be computed in a triple store.
By creating so many indexes in Elasticsearch on a per document root basis, they are readily available to prune the candidate search results.



 